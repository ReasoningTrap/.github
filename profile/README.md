<!-- Banner -------------------------------------------------------------- -->
<h1 align="center">
  <img src="sketch_style.jpg" width="48" alt="logo"/>
  ReasoningTrap â€¢ Diagnosing Set for Instruction Overriding in Reasoning Models
</h1>
<p align="center">
  <b>Fine-grain evaluation &amp; RL baselines for large language models that <i>think</i>.</b><br/>
  ConditionedMath (AIME &amp; MATH500) Â· PuzzleTrivial Â· Zero-shot pipelines
</p>
<p align="center">
  <a href="https://github.com/ReasoningTrap/ReasoningTrap/actions">
    <img alt="CI" src="https://github.com/ReasoningTrap/ReasoningTrap/actions/workflows/ci.yml/badge.svg"/>
  </a>
  <a href="https://pypi.org/project/ReasoningTrap">
    <img alt="PyPI" src="https://img.shields.io/pypi/v/contradictmath.svg"/>
  </a>
  <a href="LICENSE">
    <img alt="License" src="https://img.shields.io/github/ReasoningTrap/ReasoningTrap"/>
  </a>
</p>
---

## ðŸ“œ Why ReasoningTrap?

> Current RL-tuned LLMs excel at *producing* answers, but often ignore explicit user constraints.  
> **ReasoningTrap** surfaces these failure modes with carefully crafted, *conditioned* problems.

* **Modified from Famous MATH Reasoning Benchmark** â€“ AIME & MATH500 problems altered with minimal constraints to divert reasoning paths.
* **Puzzles Trivialized by Subtle Modifications** - Well-known puzzles where a small change transforms a challenging problem into a trivial one.
* **Plug-and-play** â€“ evaluate any ðŸ¤— Transformers, vLLM or OpenAI-style chat model in two lines.  

---

## ðŸš€ Quick start
